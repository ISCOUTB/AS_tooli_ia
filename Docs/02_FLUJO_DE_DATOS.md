# Flujo de Datos y ExtracciÃ³n de InformaciÃ³n

##  Objetivo de este Documento

Explicar en detalle **cÃ³mo se extrae la informaciÃ³n de GLPI**, **cÃ³mo funciona el chatbot con IA**, y el **flujo completo de datos** desde que el usuario hace una pregunta hasta que recibe una respuesta.

---

##  Â¿CÃ³mo se Extrae la InformaciÃ³n de GLPI?

### MÃ©todo de ExtracciÃ³n: **API REST de GLPI**

**IMPORTANTE**: El sistema **NO accede directamente a la base de datos de GLPI**. En su lugar, utiliza la **API REST oficial de GLPI** para extraer informaciÃ³n de manera segura y estructurada.

### Â¿Por QuÃ© API REST y No Base de Datos Directa?

| MÃ©todo | Ventajas | Desventajas |
|--------|----------|-------------|
| **API REST**  | â€¢ MÃ©todo oficial y soportado<br>â€¢ Respeta la lÃ³gica de negocio de GLPI<br>â€¢ No rompe permisos ni integridad<br>â€¢ MÃ¡s seguro<br>â€¢ Independiente de la estructura de DB | â€¢ Ligeramente mÃ¡s lento<br>â€¢ Limitado por API |
| **Acceso Directo a DB** âŒ | â€¢ MÃ¡s rÃ¡pido<br>â€¢ Acceso a todo | â€¢ No es oficial<br>â€¢ Puede romper permisos<br>â€¢ Inseguro<br>â€¢ Dependiente de la estructura de DB<br>â€¢ No recomendado |

**DecisiÃ³n del proyecto**: Se usa **API REST** por ser el mÃ©todo oficial, seguro y mantenible.

---

## AutenticaciÃ³n con GLPI API

### Proceso de AutenticaciÃ³n

```python
# Archivo: backend/integrations/glpi_client.py

class GLPIClient:
    def init_session(self) -> bool:
        """Inicializa sesiÃ³n con GLPI"""
        
        # 1. Hacer peticiÃ³n a /initSession
        url = f"{self.base_url}/initSession"
        
        # 2. Headers requeridos
        headers = {
            "Content-Type": "application/json",
            "App-Token": self.app_token,        # Token de la aplicaciÃ³n
            "Authorization": f"user_token {self.user_token}"  # Token del usuario
        }
        
        # 3. Enviar peticiÃ³n GET
        response = requests.get(url, headers=headers)
        
        # 4. Extraer session_token
        data = response.json()
        self.session_token = data.get("session_token")
        
        # 5. Usar session_token en todas las peticiones subsecuentes
        return True
```

### Tokens Requeridos

1. **App-Token**: Identifica la aplicaciÃ³n (se crea en GLPI)
2. **User-Token**: Identifica al usuario (se crea en GLPI)
3. **Session-Token**: Token temporal de sesiÃ³n (se obtiene al iniciar sesiÃ³n)

**ConfiguraciÃ³n** (archivo `.env`):
```bash
GLPI_URL=http://ip-vm:8200/apirest.php
GLPI_APP_TOKEN=tu_app_token_aqui
GLPI_USER_TOKEN=tu_user_token_aqui
```

---

## ğŸ“¡ ExtracciÃ³n de Tickets

### Endpoint de GLPI

```
GET /apirest.php/Ticket
```

### Proceso Completo

```python
# Archivo: backend/integrations/glpi_client.py

def get_tickets(self, filters: Optional[Dict] = None, limit: int = None) -> Dict[str, Any]:
    """
    Obtiene tickets de GLPI con paginaciÃ³n automÃ¡tica
    """
    
    # 1. Construir URL
    url = f"{self.base_url}/Ticket"
    
    # 2. ParÃ¡metros de consulta
    params = {
        "expand_dropdowns": "true"  # Convierte IDs a nombres legibles
    }
    
    # 3. Aplicar filtros (ejemplo: tickets abiertos)
    if filters and filters.get("status") == "open":
        # Campo 12 = status, "notold" = todos los estados menos cerrado
        params["criteria[0][field]"] = "12"
        params["criteria[0][searchtype]"] = "equals"
        params["criteria[0][value]"] = "notold"
    
    # 4. Solicitar primera pÃ¡gina (0-99 = 100 tickets)
    params["range"] = "0-99"
    response = requests.get(url, headers=self._get_headers(), params=params)
    
    # 5. GLPI devuelve header Content-Range con el total
    # Ejemplo: "Content-Range: 0-99/1523"
    content_range = response.headers.get('Content-Range', '0-0/0')
    total_tickets = int(content_range.split('/')[-1])
    
    # 6. Obtener JSON de tickets
    tickets = response.json()
    
    # 7. Si hay mÃ¡s tickets, paginar automÃ¡ticamente
    if len(tickets) < total_tickets and len(tickets) < 10000:  # LÃ­mite: 10k
        all_tickets = list(tickets)
        page = 1
        
        while len(all_tickets) < min(total_tickets, 10000):
            start = page * 100
            end = start + 99
            params["range"] = f"{start}-{end}"
            
            response = requests.get(url, headers=self._get_headers(), params=params)
            page_tickets = response.json()
            
            if not page_tickets:
                break
            
            all_tickets.extend(page_tickets)
            page += 1
        
        tickets = all_tickets
    
    # 8. Generar estadÃ­sticas
    stats = self._generate_ticket_stats(tickets)
    
    # 9. Devolver estructura completa
    return {
        "tickets": tickets,        # Lista de tickets
        "total": total_tickets,    # Total en GLPI
        "showing": len(tickets),   # Cantidad descargada
        "stats": stats             # EstadÃ­sticas calculadas
    }
```

### Estructura de Respuesta de GLPI

```json
[
  {
    "id": 123,
    "name": "Problema con impresora",
    "status": 2,                              // ID numÃ©rico
    "status_friendlyname": "En Proceso",      // Texto (por expand_dropdowns)
    "priority": 3,
    "priority_friendlyname": "Media",
    "type": 1,
    "content": "La impresora no imprime...",
    "date_creation": "2024-11-20 10:30:00",
    "date_mod": "2024-11-25 14:20:00",
    "users_id_recipient_friendlyname": "Juan PÃ©rez",
    "entities_id_friendlyname": "TI - Sede Central"
  },
  ...
]
```

---

##  ExtracciÃ³n de Inventario (Computadoras)

### Endpoint de GLPI

```
GET /apirest.php/Computer
```

### Proceso

```python
def get_computers(self, filters: Optional[Dict] = None) -> List[Dict]:
    """Obtiene computadoras del inventario"""
    
    url = f"{self.base_url}/Computer"
    params = {"expand_dropdowns": "true"}
    
    # Filtro por nombre (opcional)
    if filters and filters.get("name"):
        params["criteria[0][field]"] = "1"  # Campo nombre
        params["criteria[0][searchtype]"] = "contains"
        params["criteria[0][value]"] = filters["name"]
    
    response = requests.get(url, headers=self._get_headers(), params=params)
    return response.json()
```

### Estructura de Respuesta

```json
[
  {
    "id": 45,
    "name": "PC-ADMIN-01",
    "computermodels_id_friendlyname": "HP EliteDesk 800",
    "locations_id_friendlyname": "Edificio A - Piso 3",
    "manufacturers_id_friendlyname": "HP",
    "states_id_friendlyname": "En uso",
    "serial": "XYZ123456",
    "otherserial": "INV-2024-045",
    "uuid": "550e8400-e29b-41d4-a716-446655440000",
    "users_id_friendlyname": "MarÃ­a GarcÃ­a",
    "comment": "Equipo asignado a contabilidad"
  },
  ...
]
```

---

##  Â¿CÃ³mo Funciona el Chatbot con IA?

### Componentes del Sistema de IA

1. **Groq API**: Servicio cloud que proporciona acceso a modelos LLaMA
2. **Modelo**: LLaMA 3.3-70B-Versatile (70 mil millones de parÃ¡metros)
3. **AI Agent**: Clase Python que orquesta las llamadas a Groq

### Arquitectura del AI Agent

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AI Agent (Python)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. understand_query()                                 â”‚ â”‚
â”‚  â”‚     â€¢ Recibe pregunta del usuario                      â”‚ â”‚
â”‚  â”‚     â€¢ EnvÃ­a a Groq con system prompt                   â”‚ â”‚
â”‚  â”‚     â€¢ Extrae intenciÃ³n y parÃ¡metros                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  2. generate_response()                                â”‚ â”‚
â”‚  â”‚     â€¢ Recibe datos de GLPI + consulta                  â”‚ â”‚
â”‚  â”‚     â€¢ EnvÃ­a a Groq con contexto                        â”‚ â”‚
â”‚  â”‚     â€¢ Genera respuesta en lenguaje natural             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

##  Fase 1: ComprensiÃ³n de IntenciÃ³n (understand_query)

### System Prompt

El AI Agent tiene un **system prompt** que define su comportamiento:

```python
# Archivo: backend/ai/agent.py

system_prompt = """
Eres un asistente de IA profesional para el sistema GLPI IT Service Management.

Intenciones disponibles:
- "consultar_tickets": Ver lista de tickets o estadÃ­sticas
- "buscar_ticket": Buscar un ticket especÃ­fico por ID
- "consultar_inventario": Ver inventario de computadoras
- "buscar_equipo": Buscar una computadora especÃ­fica
- "generar_reporte": Generar reportes
- "consulta_general": Preguntas generales sobre GLPI

Formato de respuesta JSON:
{
    "intencion": "tipo_intencion",
    "parametros": {
        "clave": "valor"
    },
    "respuesta_usuario": "mensaje de confirmaciÃ³n profesional",
    "confianza": 0.95
}
"""
```

### Proceso de ComprensiÃ³n

```python
def understand_query(self, user_query: str) -> Dict[str, Any]:
    """
    Procesa una consulta del usuario y extrae intenciÃ³n + parÃ¡metros
    """
    
    # 1. Enviar a Groq API
    response = self.client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_query}
        ],
        temperature=0.3,              # Baja temperatura = mÃ¡s preciso
        max_tokens=500,
        response_format={"type": "json_object"}  # Forzar JSON
    )
    
    # 2. Extraer respuesta
    content = response.choices[0].message.content
    result = json.loads(content)
    
    # 3. Resultado
    return result
```

### Ejemplos de Procesamiento

#### Ejemplo 1: Consulta Simple

**Input Usuario**: `"Â¿CuÃ¡ntos tickets hay abiertos?"`

**Salida del AI Agent**:
```json
{
  "intencion": "consultar_tickets",
  "parametros": {
    "status": "open",
    "usuario": "todos"
  },
  "respuesta_usuario": "Consultando tickets abiertos.",
  "confianza": 0.98
}
```

#### Ejemplo 2: BÃºsqueda EspecÃ­fica

**Input Usuario**: `"MuÃ©strame el ticket 456"`

**Salida del AI Agent**:
```json
{
  "intencion": "buscar_ticket",
  "parametros": {
    "ticket_id": 456
  },
  "respuesta_usuario": "Recuperando ticket #456.",
  "confianza": 0.99
}
```

#### Ejemplo 3: Inventario

**Input Usuario**: `"Busca la computadora de MarÃ­a"`

**Salida del AI Agent**:
```json
{
  "intencion": "buscar_equipo",
  "parametros": {
    "nombre": "marÃ­a",
    "tipo": "Computer"
  },
  "respuesta_usuario": "Buscando la computadora de MarÃ­a.",
  "confianza": 0.92
}
```

---

## OrquestaciÃ³n: Agent Service

El **Agent Service** coordina el AI Agent con el GLPI Client:

```python
# Archivo: backend/services/agent_service.py

async def process_query(self, user_query: str) -> Dict[str, Any]:
    """
    Procesa una consulta completa
    """
    
    # PASO 1: Entender la intenciÃ³n con IA
    understanding = self.ai.understand_query(user_query)
    intention = understanding.get("intencion")
    params = understanding.get("parametros", {})
    
    # PASO 2: Ejecutar acciÃ³n en GLPI segÃºn la intenciÃ³n
    if intention == "consultar_tickets":
        glpi_data = self.glpi.get_tickets({"status": params.get("status")})
    
    elif intention == "buscar_ticket":
        ticket_id = params.get("ticket_id")
        glpi_data = self.glpi.get_ticket_by_id(ticket_id)
    
    elif intention == "consultar_inventario":
        glpi_data = self.glpi.get_computers()
    
    elif intention == "buscar_equipo":
        nombre = params.get("nombre")
        glpi_data = self.glpi.get_computers({"name": nombre})
    
    # PASO 3: Generar respuesta en lenguaje natural
    response_message = self.ai.generate_response(
        user_query,
        glpi_data,
        intention
    )
    
    return {
        "success": True,
        "message": response_message,
        "data": glpi_data,
        "intention": intention
    }
```

---

## Fase 2: GeneraciÃ³n de Respuesta Natural (generate_response)

### Proceso

```python
def generate_response(self, user_query: str, data: Any, intention: str) -> str:
    """
    Genera respuesta en lenguaje natural basada en datos de GLPI
    """
    
    # 1. Preparar contexto para la IA
    # Si hay estadÃ­sticas, usarlas (evita enviar miles de tickets)
    if isinstance(data, dict) and "stats" in data:
        total = data.get("total", 0)
        showing = data.get("showing", 0)
        stats = data["stats"]
        
        context_prompt = f"""
User Query: "{user_query}"

GLPI SYSTEM ANALYSIS - {total} TOTAL TICKETS
Dataset: {showing} tickets analyzed from {total} total records

STATISTICAL BREAKDOWN:

Status Distribution:
{self._format_stats_section(stats.get("por_estado", {}))}

Priority Distribution:
{self._format_stats_section(stats.get("por_prioridad", {}))}

Type Distribution:
{self._format_stats_section(stats.get("por_tipo", {}))}

Provide a professional response in Spanish.
"""
    
    # 2. Enviar a Groq con el contexto
    response = self.client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[
            {"role": "system", "content": "You are a professional GLPI assistant."},
            {"role": "user", "content": context_prompt}
        ],
        temperature=0.7,
        max_tokens=800
    )
    
    # 3. Devolver respuesta generada
    return response.choices[0].message.content
```

### Ejemplo de Respuesta Generada

**Query**: `"Â¿CuÃ¡ntos tickets hay abiertos?"`

**Datos GLPI**: 1523 tickets totales, 1000 analizados, estadÃ­sticas por estado

**Respuesta Generada por IA**:
```
 AnÃ¡lisis de Tickets Abiertos

Total en sistema: 1,523 tickets
Analizados: 1,000 tickets

**DistribuciÃ³n por Estado:**
â€¢ En Proceso (Asignado): 456 tickets (45.6%)
â€¢ Nuevo: 312 tickets (31.2%)
â€¢ En Espera: 232 tickets (23.2%)

**DistribuciÃ³n por Prioridad:**
â€¢ Media: 512 tickets (51.2%)
â€¢ Alta: 298 tickets (29.8%)
â€¢ Baja: 190 tickets (19.0%)

**Insights:**
- La mayorÃ­a de tickets estÃ¡n en proceso de resoluciÃ³n
- MÃ¡s del 50% tienen prioridad media
- Se recomienda revisar los 312 tickets nuevos pendientes de asignaciÃ³n

Â¿Necesitas mÃ¡s detalles sobre algÃºn estado especÃ­fico?
```

---

## Flujo Completo: De Pregunta a Respuesta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Usuario pregunta: "Â¿CuÃ¡ntos tickets hay abiertos?"              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend â†’ POST /api/v1/query                                    â”‚
â”‚  { "query": "Â¿CuÃ¡ntos tickets hay abiertos?" }                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend: Agent Service â†’ AIAgent.understand_query()             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI Agent â†’ Groq API (LLaMA 3.3)                                 â”‚
â”‚  "Analiza esta pregunta y extrae intenciÃ³n + parÃ¡metros"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Groq devuelve JSON:                                             â”‚
â”‚  { "intencion": "consultar_tickets",                             â”‚
â”‚    "parametros": {"status": "open"} }                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent Service â†’ GLPIClient.get_tickets({"status": "open"})      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GLPI Client â†’ API REST de GLPI                                  â”‚
â”‚  GET /apirest.php/Ticket?criteria[0][field]=12&...               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GLPI devuelve JSON con tickets + header Content-Range           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GLPI Client procesa y pagina (si hay mÃ¡s de 100 tickets)        â”‚
â”‚  Genera estadÃ­sticas automÃ¡ticas                                 â”‚
â”‚  Devuelve: { tickets, total, showing, stats }                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent Service â†’ AIAgent.generate_response()                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI Agent â†’ Groq API (LLaMA 3.3)                                  â”‚
â”‚  "Genera respuesta profesional con estos datos estadÃ­sticos"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Groq devuelve texto en lenguaje natural                         â”‚
â”‚  " AnÃ¡lisis de Tickets Abiertos..."                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend â†’ Frontend: JSON con respuesta                          â”‚
â”‚  { "success": true, "message": "...", "data": {...} }            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend renderiza mensaje en el chat                           â”‚
â”‚  Usuario ve la respuesta formateada                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Resumen: ExtracciÃ³n de InformaciÃ³n

1. **MÃ©todo**: API REST de GLPI
2. **AutenticaciÃ³n**: App-Token + User-Token â†’ Session-Token
3. **Endpoints principales**:
   - `/Ticket` - Tickets
   - `/Computer` - Inventario
   - `/search/{itemType}` - BÃºsquedas avanzadas
4. **PaginaciÃ³n**: AutomÃ¡tica (100 items por pÃ¡gina, hasta 10,000 mÃ¡ximo)
5. **OptimizaciÃ³n**: Genera estadÃ­sticas localmente para reducir tokens enviados a IA

## Resumen: Funcionamiento del Bot

1. **IA utilizada**: Groq API con modelo LLaMA 3.3-70B-Versatile
2. **Dos fases**:
   - **ComprensiÃ³n**: Extrae intenciÃ³n y parÃ¡metros del texto del usuario
   - **GeneraciÃ³n**: Crea respuesta en lenguaje natural basada en datos de GLPI
3. **OrquestaciÃ³n**: Agent Service coordina IA + GLPI
4. **Formato**: System prompts definen el comportamiento de la IA
5. **JSON estructurado**: La IA devuelve datos estructurados, no texto libre

---

## Notas Importantes

- **Seguridad**: Nunca se accede directamente a la base de datos de GLPI
- **Escalabilidad**: El sistema puede manejar miles de tickets gracias a paginaciÃ³n y estadÃ­sticas
- **Flexibilidad**: System prompts se pueden ajustar para cambiar el comportamiento de la IA
- **Costo**: Groq API es gratuita hasta cierto lÃ­mite de uso
- **Latencia**: TÃ­picamente 1-3 segundos por consulta completa (IA + GLPI)
